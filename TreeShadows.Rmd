---
title: 'Report: Tree Shadows'
author: "Massimo Palme"
date: "21/6/2020"
output:
  word_document: default
  pdf_document: default
---

Install packages if needed

```{r}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
library(tidyverse)
library(caret)
library(data.table)
library(tibble)
library(pillar)
library(readr)
```
Read data


```{r}
dat <- read_csv("Shadows.csv")
data<-data.frame(dat)
v<-read.csv("z.csv",header=FALSE)
rep<-read.csv("rep.csv",header=FALSE)
```
Generate train and test set. We choose a 25% of cases to be in the test set. More than 25% is difficult because of the low number of data available. Less than 25% could lead to not very credible results.


```{r}
set.seed(3, sample.kind = "Rounding")
test_index<-createDataPartition(data$saving,times=1,p=0.25,list=FALSE)
test_set <- data[test_index, ]
train_set <- data[-test_index, ]

test_v<-v[test_index, ]
test_rep<-rep[test_index, ]
```
Train different algorithms (Knn, Random forest, Glm and Loess)

```{r}
train_knn<-train(saving~.,method="knn",data=train_set)
y_hat_knn<-predict(train_knn,test_set,type="raw")

train_rf<-train(saving~.,method="rf",data=train_set)
y_hat_rf<-predict(train_rf,test_set,type="raw")

train_gamLoess<-train(saving~.,method="gamLoess",data=train_set)
y_hat_gamLoess<-predict(train_gamLoess,test_set,type="raw")

train_glm<-train(saving~.,method="glm",data=train_set)
y_hat_glm<-predict(train_glm,test_set,type="raw")
```
Construct an ensamble and check the RMSE

```{r}
y_hat_resp_ensamble<-(y_hat_gamLoess+y_hat_glm+y_hat_knn+y_hat_rf)/4

RMSE_5<-sqrt(mean((y_hat_resp_ensamble-test_set$saving)^2))
RMSE_2<-sqrt(mean((y_hat_rf-test_set$saving)^2))
RMSE_1<-sqrt(mean((y_hat_knn-test_set$saving)^2))
RMSE_3<-sqrt(mean((y_hat_glm-test_set$saving)^2))
RMSE_4<-sqrt(mean((y_hat_gamLoess-test_set$saving)^2))
mean(test_set$saving)


options(pillar.sigfig=3)

rmse_results <- tibble(method = c("Knn","Rf","Glm","Loess","Ensamble"), RMSE = c(RMSE_1,RMSE_2,RMSE_3,RMSE_4,RMSE_5))

rmse_results
```
RMSE is more than the 30% of the mean value of saving. It will be difficult to predict the saving with a reasonable confiance interval. However, a practical tool to be used in planning does not need to present a numerical value as a result. It could be very useful a tool that helps planners to decide weather or not to plant a row of trees in each configuration. We established a treshold value of 15%: under this value it is not reccomended to plant the trees. Now, we can use machine learning approach to predict if the saving will be more or less than the treshold, and check the accuracy.

```{r}
y_hat_1<-ifelse(y_hat_knn>15,"Y","N")
y_hat_1<-as.factor(y_hat_1)
confusionMatrix(y_hat_1,test_v)
accuracy_1<-confusionMatrix(y_hat_1,test_v)$overall["Accuracy"]
```
So Knn predicts the Y/N selection with a 82% of accuracy. Try the other algorithms:
```{r}
y_hat_2<-ifelse(y_hat_rf>15,"Y","N")
y_hat_2<-as.factor(y_hat_2)
confusionMatrix(y_hat_2,test_v)
varImp(train_rf)
accuracy_2<-confusionMatrix(y_hat_2,test_v)$overall["Accuracy"]

y_hat_3<-ifelse(y_hat_gamLoess>15,"Y","N")
y_hat_3<-as.factor(y_hat_3)
confusionMatrix(y_hat_3,test_v)
accuracy_3<-confusionMatrix(y_hat_3,test_v)$overall["Accuracy"]

y_hat_4<-ifelse(y_hat_glm>15,"Y","N")
y_hat_4<-as.factor(y_hat_4)
confusionMatrix(y_hat_4,test_v)
accuracy_4<-confusionMatrix(y_hat_4,test_v)$overall["Accuracy"]

y_hat_ensamble<-ifelse(y_hat_resp_ensamble>15,"Y","N")
y_hat_ensamble<-as.factor(y_hat_ensamble)
confusionMatrix(y_hat_ensamble,test_v)
accuracy_5<-confusionMatrix(y_hat_ensamble,test_v)$overall["Accuracy"]

accuracy_results<-tibble(method = c("Knn","Rf","Glm","Loess","Ensamble"), Accuracy = c(accuracy_1,accuracy_2,accuracy_3,accuracy_4,accuracy_5))

accuracy_results
```
We see that most of the algorithms can predict the option Y/N with more than a 90% of accuracy. Best performance is the ensamble with a 97% of accuracy.

The Random forest approach is very interesting because we can see which predictors are the most important in selection: the number of fachades shaded (used the 100% of times), the tree type (pinus permits to shade better the buildings), and the distance from the fachade (the bigger the distance, the lower the shadow). Then the angular desviation between the row of trees and the fachade and the plan shape of the building (buildings with "I" shape performe in general better than others, due to the fact that is esaier to shadow the main fachade).

Another interesting result of Rf algorithms is the sensitivity (100%). In the urban planning problem sensitivity should be priviledged respect to specifcity because the most important thing is not to choose as favourable (Y) a case that it is really not (N). So Rf approach assure that the minimum of 15% energy saving is obtained. 

The ensamble has also a sensitivity of 100% and a better specificity. It actually predict correctly 32 cases of 33. 

Now, we can also try to establish more than two classes. For example, we can decide that for savings less than 5% there is a "very low" saving, for savings between 5 and 15% a "low" saving, for savings between 15 and 25% a "medium" saving, for savings between 25 and 35% a "high" saving and for savings more than 35% a "very high" saving. 

Now check the accuracy of the algorithms for this 5 classes classification:

```{r}

y_hat_resp_4<-ifelse(y_hat_gamLoess<5,"very low",ifelse(y_hat_gamLoess<15,"low",ifelse(y_hat_gamLoess<25,"medium",ifelse(y_hat_gamLoess<35,"high","very high"))))
y_hat_resp_4<-as.factor(y_hat_resp_4)
confusionMatrix(y_hat_resp_4,test_rep)
accuracy_resp_4<-confusionMatrix(y_hat_resp_4,test_rep)$overall["Accuracy"]

y_hat_resp_3<-ifelse(y_hat_glm<5,"very low",ifelse(y_hat_glm<15,"low",ifelse(y_hat_glm<25,"medium",ifelse(y_hat_glm<35,"high","very high"))))
y_hat_resp_3<-as.factor(y_hat_resp_3)
confusionMatrix(y_hat_resp_3,test_rep)
accuracy_resp_3<-confusionMatrix(y_hat_resp_3,test_rep)$overall["Accuracy"]

y_hat_resp_2<-ifelse(y_hat_rf<5,"very low",ifelse(y_hat_rf<15,"low",ifelse(y_hat_rf<25,"medium",ifelse(y_hat_rf<35,"high","very high"))))
y_hat_resp_2<-as.factor(y_hat_resp_2)
confusionMatrix(y_hat_resp_2,test_rep)
accuracy_resp_2<-confusionMatrix(y_hat_resp_2,test_rep)$overall["Accuracy"]

y_hat_resp_1<-ifelse(y_hat_knn<5,"very low",ifelse(y_hat_knn<15,"low",ifelse(y_hat_knn<25,"medium",ifelse(y_hat_knn<35,"high","very high"))))
y_hat_resp_1<-as.factor(y_hat_resp_1)
confusionMatrix(y_hat_resp_1,test_rep)
accuracy_resp_1<-confusionMatrix(y_hat_resp_1,test_rep)$overall["Accuracy"]


y_hat_resp_5<-ifelse(y_hat_resp_ensamble<5,"very low",ifelse(y_hat_resp_ensamble<15,"low",ifelse(y_hat_resp_ensamble<25,"medium",ifelse(y_hat_resp_ensamble<35,"high","very high"))))
y_hat_resp_5<-as.factor(y_hat_resp_5)
confusionMatrix(y_hat_resp_5,test_rep)
accuracy_resp_5<-confusionMatrix(y_hat_resp_5,test_rep)$overall["Accuracy"]


accuracy_resp_results<-tibble(method = c("Knn","Rf","Glm","Loess","Ensamble"), Accuracy_cat = c(accuracy_resp_1,accuracy_resp_2,accuracy_resp_3,accuracy_resp_4,accuracy_resp_5))

accuracy_resp_results
```
In this case, we obtain accuracy of 76% with the ensamble, not bad but it should be further improved. We will need more data (we have now only 123) to do that.
